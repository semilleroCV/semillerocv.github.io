{
    "HomePage": {
      "title": "Hello world!",
      "about": "Go to the about page",
      "description": "Transform your vision of the world: discover the power and limitless possibilities of computer vision",
      "learn_more": "Learn more"
    },
    "Hero": {
        "title": "Hands-on",
        "subtitle1": "omputer",
        "subtitle2": "ision",
        "learn_more": "Learn more"
    },
    "EventContent": {
        "title": "Schedule",
        "session1_title": "Session 1",
        "session1_subject": "Session 1: Pilot",
        "session1_des": "Introduction to the seedbed.",
        "session2_title": "Session 2",
        "session2_subject": "Session 2: From photons to pixels",
        "session2_des": "Generalities about the acquisition and digital processing of images",
        "session3_title": "Session 3",
        "session3_subject": "Session 3: Deep Learning",
        "session3_des": "Unleash the power of artificial intelligence in computer vision",
        "session4_title": "Session 4",
        "session4_subject": "Session 4: Spectral Imaging",
        "session4_des": "Discover the secrets beyond a color image.",
        "session5_title": "Session 5",
        "session5_subject": "Session 5: Passive depth estimation",
        "session5_des": "Explore depth estimation techniques without external sources",
        "session6_title": "Session 6",
        "session6_subject": "Session 6: Active depth estimation",
        "session6_des": "Extracting depth with millimeter precision from light.",
        "session7_title": "Session 7",
        "session7_subject": "Session 7: Project allocation",
        "session7_des": "Challenge yourself üî•üî•",
        "session8_title": "Session 8",
        "session8_subject": "Session 8: Segmentation",
        "session8_des": "Delineating the digital world through meticulously classified pixels",
        "session9_title": "Session 9",
        "session9_subject": "Session 9: Thermal imaging",
        "session9_des": "The world seen through heat",
        "session10_title": "Session 10",
        "session10_subject": "Session 10: Convex Optimization",
        "session10_des": "Optimizing the world with mathematics",
        "session11_title": "Session 11",
        "session11_subject": "Session 11: NLP",
        "session11_des": "Learning to talk to machines",
        "session12_title": "Session 12",
        "session12_subject": "Session 12: Final projects",
        "session12_des": "Challenge your skills üöÄ üöÄ"
    },
    "Faq": {
        "directed_by": "Directed by",
        "name": "Hoover Fabian Rueda Chac√≥n",
        "bio": "Systems and Computer Engineer, with a master's and doctorate in Electrical and Computer Engineering. He studied in Colombia and the US, being a Postdoctoral Associate at Boston University. His research areas include image processing, algorithms, computational optics, and numerical optimization."
    },
    "Layout": {
        "title": "Hands-On Computer Vision",
        "description": "Join us at the Hands-on Computer Vision Seedbed and immerse yourself in a unique experience that merges theory with practice in the fascinating world of computer vision. We will focus on advanced topics such as Computational Photography, Deep Learning, Thermal Imaging, Spectral Imaging, Depth Estimation and more"
    },
    "LumaEmbed": {
        "loading": "Loading event..."
    },
    "ProjectsCarousel": {
        "title": "üèÜ Degree Projects üèÜ",
        "project1_title": "Segmentation of Materials from RGB Images Using Vision Transformer Architectures and Multispectral Information Integration",
        "project2_title": "Simulation of a Photon Counting Camera for the Acquisition of Transient Images in Non-Line-of-Sight Scenarios",
        "project3_title": "Estimation of safe navigation speed for autonomous vehicles using computer vision techniques",
        "project4_title": "Fusion of depth images obtained with LiDAR and Stereovision systems through deep learning techniques",
        "view_pdf": "View PDF",
        "slides": "Slides",
        "code": "Code"
    },
    "SponsoredBy": {
        "title": "Research Areas",
        "area1_title": "Non-line-of-sight imaging",
        "area1_description": "Look through walls: technology to see beyond obstacles.",
        "area2_title": "Depth estimation",
        "area2_description": "Delve into the 3D world: algorithms that accurately measure distances.",
        "area3_title": "NLP",
        "area3_description": "Communicate with machines: intelligence that understands human language.",
        "area4_title": "Material segmentation",
        "area4_description": "Segment with high precision: meticulous identification of materials in images.",
        "area5_title": "Spectral imaging",
        "area5_description": "Beyond RGB: capture the full spectrum of light.",
        "area6_title": "Thermal imaging",
        "area6_description": "Visualize through heat: technology that reveals the invisible to the human eye."
    },
    "Galeria": {
        "title1": "In 2024, we explored and deepened our understanding of computer vision. This is a visual summary of the sessions that inspired learning and innovation.",
        "title2": "We are passionate about sharing the latest advances in Deep Learning. Here are some images from our study sessions and our participation in U24Fest.",
        "title3": "At HoCV, we create a space to share, collaborate, and grow together as a team, strengthening the community and collective learning."
    },
    "Nosotros": {
        "title": "Building the future of Computer Vision",
        "mission_title": "Our Mission",
        "mission_description": "We drive innovation by training the next generation of computer vision experts through research and collaborative experiences.",
        "professors_title": "Professors",
        "professor1_name": "Hoover Rueda-Chac√≥n",
        "professor1_role": "Director of the Seedbed",
        "masters_students_title": "Master's Students",
        "masters_student1_name": "Fabian P√©rez",
        "masters_student1_role": "Msc(s) Computer Science",
        "masters_student2_name": "Julian Leon",
        "masters_student2_role": "Msc(s) Applied Mathematics",
        "undergraduate_students_title": "Undergraduate Students",
        "undergraduate_student1_name": "Cristian Rey",
        "undergraduate_student1_role": "Systems Engineering Student",
        "undergraduate_student2_name": "Miguel √Ångel",
        "undergraduate_student2_role": "Systems Engineering Student",
        "undergraduate_student3_name": "Ramiro Avila",
        "undergraduate_student3_role": "Systems Engineering Student",
        "undergraduate_student4_name": "Henry Mantilla",
        "undergraduate_student4_role": "Systems Engineering Student",
        "undergraduate_student5_name": "Paula Uzcategui",
        "undergraduate_student5_role": "Systems and Biology Engineering Student",
        "undergraduate_student6_name": "Guillermo Pinto",
        "undergraduate_student6_role": "Systems Engineering Student",
        "undergraduate_student7_name": "Sebastian Solano",
        "undergraduate_student7_role": "Electronics Engineering Student",
        "undergraduate_student8_name": "Brayan Quintero",
        "undergraduate_student8_role": "Systems Engineering Student",
        "undergraduate_student9_name": "Andrea Parra",
        "undergraduate_student9_role": "Systems Engineering Student",
        "undergraduate_student10_name": "Dana Villamizar",
        "undergraduate_student10_role": "Systems Engineering Student",
        "undergraduate_student11_name": "Jorge Garcia",
        "undergraduate_student11_role": "Systems Engineering Student",
        "undergraduate_student12_name": "Juan Toloza",
        "undergraduate_student12_role": "Systems Engineering Student",
        "undergraduate_student13_name": "Sneider S√°nchez",
        "undergraduate_student13_role": "Systems Engineering Student",
        "undergraduate_student14_name": "Juan Calderon",
        "undergraduate_student14_role": "Systems Engineering Student",
        "undergraduate_student15_name": "Valentina P√©rez",
        "undergraduate_student15_role": "Systems Engineering Student",
        "undergraduate_student16_name": "Miguel Pimiento",
        "undergraduate_student16_role": "Systems Engineering Student",
        "undergraduate_student17_name": "C√©sar Vanegas",
        "undergraduate_student17_role": "Systems Engineering Student"
    },
    "Sesiones": {
        "session1_title": "Pilot",
        "session1_location": "Introduction",
        "session1_description": "Introduction to the seedbed",
        "session2_title": "From photons to pixels",
        "session2_location": "Fundamentals",
        "session2_description": "Generalities about the acquisition and digital processing of images",
        "session3_title": "Deep Learning",
        "session3_location": "AI & CV",
        "session3_description": "Unleash the power of artificial intelligence in computer vision",
        "session4_title": "Spectral Imaging",
        "session4_location": "Processing",
        "session4_description": "Discover the secrets beyond a color image.",
        "session5_title": "Passive depth estimation",
        "session5_location": "3D Vision",
        "session5_description": "Explore depth estimation techniques without external sources",
        "session6_title": "Active depth estimation",
        "session6_location": "3D Vision",
        "session6_description": "Extracting depth with millimeter precision from light.",
        "session7_title": "Project allocation",
        "session7_location": "Projects",
        "session7_description": "Challenge yourself üî•üî•",
        "session8_title": "Segmentation",
        "session8_location": "Processing",
        "session8_description": "Delineating the digital world through meticulously classified pixels",
        "session9_title": "Thermal imaging",
        "session9_location": "Processing",
        "session9_description": "The world seen through heat",
        "session10_title": "Convex Optimization",
        "session10_location": "Mathematics",
        "session10_description": "Optimizing the world with mathematics",
        "session11_title": "NLP",
        "session11_location": "AI",
        "session11_description": "Learning to talk to machines",
        "session12_title": "Final projects",
        "session12_location": "Projects",
        "session12_description": "Challenge your skills üöÄ üöÄ"
    },
    "Sesion1": {
        "sidebar_introduccion": "Introduction and Objectives",
        "sidebar_lecturas": "Previous Resources",
        "sidebar_contenido": "Session Development",
        "sidebar_actividades": "Subsequent Activities",
        "sidebar_sesion": "Session Content",
        "hero_title": "Pilot: Introduction to the Seedbed",
        "hero_description": "Welcome to the first session of the seedbed. Here we lay the foundations to explore the fascinating world of computer vision and define the objectives that will accompany us on this exciting journey.",
        "introduccion_title": "Introduction and Objectives",
        "introduccion_description": "In this introductory session, we present the context and objectives of the seedbed. We will explore the history, importance, and current applications of computer vision, laying the groundwork for delving into more advanced concepts.",
        "lecturas_title": "Resources and Previous Readings",
        "lecturas_description": "Before attending the session, we recommend that you review the following resources to familiarize yourself with the basic concepts:",
        "lecturas_link1": "\"How we're teaching computers to understand pictures\"",
        "lecturas_link2": "What is computer vision?",
        "contenido_title": "Session Development",
        "contenido_description1": "During this session, we combine theory and practice. Through presentations and live demonstrations, we address topics such as image acquisition and processing, fundamentals of Deep Learning, and visual analysis techniques. Everything is developed in a dynamic and participatory manner.",
        "contenido_description2": "We encourage interaction and debate, allowing you to experiment with real examples and lay the groundwork for future projects.",
        "actividades_title": "Subsequent Activities and Tasks",
        "actividades_description1": "At the end of the session, you will be assigned practical activities to consolidate the knowledge acquired. These tasks will allow you to experiment autonomously and prepare the ground for the following modules.",
        "actividades_description2": "In addition, we will promote the exchange of ideas in groups, allowing for the discussion and resolution of doubts in a collaborative environment.",
        "sesion_title": "Session Content",
        "sesion_presentacion_title": "PDF Presentation",
        "sesion_presentacion_description": "You can navigate through the presentation using the viewer controls.",
        "sesion_video_title": "Session Video"
    },
    "Sesion2": {
        "sidebar_introduccion": "Introduction and Objectives",
        "sidebar_lecturas": "Resources and Previous Readings",
        "sidebar_contenido": "Session Development",
        "sidebar_actividades": "Subsequent Activities and Tasks",
        "sidebar_sesion": "Session Content",
        "hero_title": "From Photons to Pixels",
        "hero_description": "In this session, we explore the transition from light to digital image. We will delve into the fundamental principles of image formation, from optical concepts to digital processing, establishing the essential foundations for understanding how cameras capture and process light.",
        "introduccion_title": "Introduction and Objectives",
        "introduccion_description": "The objective of this session is to understand the physical and mathematical principles that allow the capture of images. We will explore the relationship between optics, sensors, and the algorithms that convert light into processable data. This session will serve as a basis for understanding advanced image analysis and manipulation techniques in future sessions.",
        "lecturas_title": "Resources and Previous Readings",
        "lecturas_description": "Before attending the session, we recommend that you review the following resources to familiarize yourself with the basic concepts:",
        "lecturas_link1": "TED-EdLight waves, visible and invisible",
        "lecturas_link2": "Basics Explained, H3VtuxDigital vs Analog. What's the Difference? Why Does it Matter...",
        "lecturas_link3": "TED-EdCamera or eye: Which sees better? - Michael Mauser",
        "lecturas_link4": "Understanding digital camera sensors",
        "lecturas_link5": "Color image Demosaicing",
        "lecturas_link6": "How to Turn a Room into a Camera Obscura",
        "lecturas_link7": "Vermeer and the Camera Obscura: Part I",
        "contenido_title": "Session Development",
        "contenido_description": "In this session, we combine theory and practice to explore the following topics:",
        "contenido_list_item1": "Image formation: Explanation of the concept of the camera obscura, the propagation of light, and the relationship between the field of view (FOV), the angle of view (AOV), and the depth of field (DoF).",
        "contenido_list_item2": "The exposure triangle: Analysis of shutter speed, aperture, and ISO sensitivity.",
        "contenido_list_item3": "Digital images: Transformation from a continuous to a digital domain, bit depth, and types of images (binary, grayscale, color, spectral, video, etc.).",
        "contenido_list_item4": "Optical sensors: Anatomy of a sensor, differences between CMOS and CCD, white balance, demosaicking, and image noise.",
        "contenido_list_item5": "Image processing pipeline: Stages of processing from capture to the final image.",
        "contenido_list_item6": "Image transformations: Gamma correction, histogram equalization, linear filtering, and 2D convolution.",
        "contenido_footer": "The session will be participatory and will include practical demonstrations to reinforce the theoretical concepts.",
        "actividades_title": "Subsequent Activities and Tasks",
        "actividades_description": "At the end of the session, practical exercises will be assigned to consolidate the knowledge acquired. These activities will include:",
        "actividades_list_item1": "Experimentation with a homemade camera obscura.",
        "actividades_list_item2": "Basic implementation of gamma correction and histogram equalization.",
        "sesion_title": "Session Content",
        "sesion_presentacion_title": "PDF Presentation",
        "sesion_presentacion_description": "You can navigate through the presentation using the viewer controls.",
        "sesion_video_title": "Session Video"
    },
    "Sesion3": {
        "sidebar_introduccion": "Introduction and Objectives",
        "sidebar_lecturas": "Resources and Previous Readings",
        "sidebar_contenido": "Session Development",
        "sidebar_actividades": "Subsequent Activities and Tasks",
        "sidebar_sesion": "Session Content",
        "hero_title": "Deep Learning",
        "hero_description": "In this session, we dive into the fascinating world of Deep Learning, exploring from its fundamental principles to its most recent applications. From building a multilayer perceptron from scratch to analyzing convolutional neural networks, we will discover how these technologies are transforming our interaction with the visual world.",
        "introduccion_title": "Introduction and Objectives",
        "introduccion_description": "The main objective of this session is to understand the fundamentals of Deep Learning and its application in computer vision. We will explore the historical evolution of this technology, understand its basic mathematical principles, and analyze where the field is heading. By the end, you will be able to understand how a multilayer perceptron is built from scratch, recognize the functioning of convolutional neural networks, and visualize the current and future trends of Deep Learning.",
        "lecturas_title": "Resources and Previous Readings",
        "lecturas_description": "To make the most of this session, we recommend that you review the following resources:",
        "lecturas_link1": "Andrej Karpathy's Talk: Building Generative Models",
        "lecturas_link2": "3Blue1Brown Series: Neural Networks",
        "lecturas_link3": "TensorFlow Playground - Interactive Experimentation",
        "contenido_title": "Session Development",
        "contenido_description": "During this session, we will explore:",
        "contenido_list_item1": "What is Deep Learning? Definition, brief history, and differences with other forms of machine learning.",
        "contenido_list_item2": "Practical applications: Use cases in industry and research, with an emphasis on computer vision.",
        "contenido_list_item3": "Mathematical foundations: Understanding the basic principles that allow neural networks to function.",
        "contenido_list_item4": "Non-linearity: Importance of activation functions and how they allow modeling complex relationships.",
        "contenido_list_item5": "Cost functions (Losses): Measurement of error and optimization of model performance.",
        "contenido_list_item6": "Backpropagation and SGD: Fundamental algorithms for training neural networks.",
        "contenido_list_item7": "Interpretation of weights and biases: Understanding what the parameters of a network really represent.",
        "contenido_list_item8": "Convolutional neural networks: Specialized architecture for image processing.",
        "contenido_list_item9": "Current trends: Where the field of Deep Learning is heading and what we can expect in the future.",
        "contenido_footer": "We will implement a multilayer perceptron from scratch to deeply understand its internal functioning, and we will analyze practical examples to reinforce the theoretical concepts.",
        "sesion_title": "Session Content",
        "sesion_presentacion_title": "PDF Presentation",
        "sesion_presentacion_description": "You can navigate through the presentation using the viewer controls.",
        "sesion_video_title": "Session Video"
    },
    "Sesion4": {
        "sidebar_introduccion": "Introduction and Objectives",
        "sidebar_lecturas": "Resources and Previous Readings",
        "sidebar_contenido": "Session Development",
        "sidebar_actividades": "Subsequent Activities and Tasks",
        "hero_title": "Spectral Imaging",
        "hero_description": "This session presents the fundamental concepts of spectral imaging. To build a comprehensive definition of this field, topics such as the electromagnetic spectrum, remote sensing, and spectral signature will be explored. In addition, its main applications and the different acquisition methods will be addressed. Finally, since the capture of these images in a real context involves optical principles, phenomena such as the dispersion and diffraction of light will be analyzed.",
        "introduccion_title": "Introduction and Objectives",
        "introduccion_description": "The objective of this session is to develop a comprehensive notion of the field of spectral imaging, covering from the physical phenomena involved to the main applications and characteristics of this type of acquisition.",
        "lecturas_title": "Resources and Previous Readings",
        "lecturas_description": "To make the most of this session, we recommend that you review the following resources:",
        "lecturas_link1": "Mapping the Invisible: Introduction to Spectral Remote Sensing",
        "lecturas_link2": "Hyperspectral Imaging - eoPortal",
        "lecturas_link3": "Getting Started with Hyperspectral Image Processing",
        "lecturas_link4": "Hyperspectral image analysis with Python made easy",
        "contenido_title": "Session Development",
        "contenido_description": "In accordance with the Hands-On methodology, this session will combine the exploration of theory with its practical application:",
        "contenido_list_item1": "Introduction to spectral imaging: What they are, how they are classified, their relationship with the electromagnetic spectrum, their acquisition through remote sensing, and the concept of spectral signature.",
        "contenido_list_item2": "Applications: Classification of materials, detection of characteristics not visible to the naked eye, monitoring by satellite, among others.",
        "contenido_list_item3": "Acquisition methods: Pixel by pixel, line by line, band by band, and all in one.",
        "contenido_list_item4": "Physical phenomena: Dispersion and diffraction, advanced acquisition methods",
        "contenido_footer": "Throughout the session, practical activities will be included as appropriate.",
        "sesion_title": "Session Content",
        "sesion_presentacion_title": "PDF Presentation",
        "sesion_presentacion_description": "You can navigate through the presentation using the viewer controls.",
        "sesion_video_title": "Session Video"
    },
    "Sesion5": {
        "sidebar_introduccion": "Introduction and Objectives",
        "sidebar_lecturas": "Resources and Previous Readings",
        "sidebar_contenido": "Session Development",
        "sidebar_actividades": "Subsequent Activities and Tasks",
        "hero_title": "Passive Depth Estimation",
        "hero_description": "This session explores the fundamental principles of passive depth estimation. It will analyze how visual systems extract three-dimensional information from images, covering key concepts such as depth perception and disparity. Special emphasis will be placed on techniques such as stereo vision, detailing the necessary steps for the 3D reconstruction of the scene. In addition, modern approaches based on deep learning methods will be included, exploring their applications in areas such as robotics and autonomous vehicles.",
        "introduccion_title": "Introduction and Objectives",
        "introduccion_description": "The objective of this session is to understand the principles behind depth estimation, exploring the complete process necessary to transform 2D images into 3D representations. The techniques and steps involved will be detailed, from the capture of the images to the precise three-dimensional reconstruction.",
        "lecturas_title": "Resources and Previous Readings",
        "lecturas_description": "To make the most of this session, we recommend that you review the following resources:",
        "lecturas_link1": "Depth Perception",
        "lecturas_link2": "Stereo Vision: Depth Estimation between object and camera",
        "lecturas_link3": "The State of the Art of Depth Estimation from Single Images",
        "lecturas_link4": "Disparity and Depth Estimation From Stereo Camera",
        "lecturas_link5": "Simple Stereo | Camera Calibration",
        "lecturas_link6": "Structure from Motion Problem | Structure from Motion",
        "contenido_title": "Session Development",
        "contenido_description": "In accordance with the Hands-On methodology, this session will combine the exploration of theory with its practical application:",
        "contenido_list_item1": "Introduction to depth perception: What depth is, how humans perceive it through their eyes, and the applications of this process in artificial vision.",
        "contenido_list_item2": "Depth estimation techniques: Passive methods (such as stereo vision) and active methods (such as LIDAR), their advantages and limitations.",
        "contenido_list_item3": "Stereo vision: Key concepts of perception, disparity, depth, projection geometry, rectification, and the Structure from Motion (SfM) technique applied through deep learning.",
        "contenido_footer": "Throughout the session, practical activities will be included as appropriate.",
        "sesion_title": "Session Content",
        "sesion_presentacion_title": "PDF Presentation",
        "sesion_presentacion_description": "You can navigate through the presentation using the viewer controls.",
        "sesion_video_title": "Session Video"
    },
    "Sesion6": {
        "sidebar_introduccion": "Introduction and Objectives",
        "sidebar_lecturas": "Resources and Previous Readings",
        "sidebar_contenido": "Session Development",
        "sidebar_actividades": "Subsequent Activities and Tasks",
        "hero_title": "Active Depth Estimation",
        "hero_description": "In this session, we will delve into the fundamentals of active depth estimation, an innovative technique that takes advantage of the detection of light in motion to estimate with high precision the distance at which an object is in a scene. This approach allows obtaining three-dimensional information in a much more precise way than traditional techniques. In addition, we will analyze the incredible applications of this approach in various areas, from robotics to autonomous vehicles and the visualization of hidden objects.",
        "introduccion_title": "Introduction and Objectives",
        "introduccion_description": "The main objective of this session is to provide a comprehensive understanding of active depth estimation and the technologies that support it, understanding how light allows us to obtain precise measurements of a scene.",
        "lecturas_title": "Resources and Previous Readings",
        "lecturas_description": "To make the most of this session, we recommend that you review the following resources:",
        "lecturas_link1": "How Structured Light works",
        "lecturas_link2": "What is TOF (Time of Flight) & How Does it Work?",
        "lecturas_link3": "ToF (Time of Flight) Technology - Industrial Use",
        "lecturas_link4": "What Is Time-of-Flight? ‚Äì Vision Campus",
        "contenido_title": "Session Development",
        "contenido_description": "In accordance with the Hands-On methodology, this session will combine the exploration of theory with its practical application:",
        "contenido_list_item1": "Depth estimation methods: Brief reminder of the previous session, difference between passive vs active depth estimation methods and the key characteristics of each one.",
        "contenido_list_item2": "Structured light: What the structured light method consists of, how this approach allows us to estimate the depth of an object by projecting light patterns, and we will explore the main applications that take advantage of this technology.",
        "contenido_list_item3": "Time of flight of light: Definition of time of flight and differences between indirect time of flight (iToF) and direct time of flight (dToF). In addition, we will see which sensors are capable of measuring light in motion and how they are used to obtain precise depth measurements.",
        "contenido_list_item4": "Interesting applications of measuring light in motion. How we can reconstruct scenes with the help of light.",
        "contenido_footer": "Throughout the session, practical activities will be included as appropriate.",
        "sesion_title": "Session Content",
        "sesion_presentacion_title": "PDF Presentation",
        "sesion_presentacion_description": "You can navigate through the presentation using the viewer controls.",
        "sesion_video_title": "Session Video"
    },
    "Sesion8": {
        "sidebar_introduccion": "Introduction and Objectives",
        "sidebar_lecturas": "Resources and Previous Readings",
        "sidebar_contenido": "Session Development",
        "sidebar_actividades": "Subsequent Activities and Tasks",
        "hero_title": "Image Segmentation",
        "hero_description": "In this session, we will explore the fundamentals and advanced techniques of image segmentation, a fundamental tool in artificial vision that allows classifying pixels into prominent regions within a scene. We will understand how different techniques, from traditional to advanced based on deep learning, can be used to interpret visual content accurately and efficiently.",
        "introduccion_title": "Introduction and Objectives",
        "introduccion_description": "The main objective of this session is to provide a comprehensive understanding of what segmentation is, how it works, its applications, and the various techniques that allow identifying significant regions in digital images, highlighting the importance of context in the precise classification of pixels.",
        "lecturas_title": "Resources and Previous Readings",
        "lecturas_description": "To make the most of this session, we recommend that you review the following resources:",
        "lecturas_link1": "Principles of Gestalt Psychology applied to visual perception.",
        "lecturas_link2": "Basic introduction to clustering algorithms.",
        "lecturas_link3": "Basic deep learning techniques for computer vision.",
        "contenido_title": "Session Development",
        "contenido_description": "In accordance with the Hands-On methodology, this session will combine the exploration of theory with its practical application:",
        "contenido_list_item1": "We will begin by defining segmentation as the classification of pixels into coherent regions, applying Gestalt principles such as proximity, similarity, and symmetry.",
        "contenido_list_item2": "Then we will explore various applications of segmentation in areas such as robotic vision, autonomous driving, and medical analysis, emphasizing the importance of visual context in precise classifications.",
        "contenido_list_item3": "Next, we will address classic segmentation techniques such as thresholding, clustering, mean-shift, SLIC, and graph-based segmentation.",
        "contenido_list_item4": "Subsequently, we will delve into the integration of advanced methods using convolutional neural networks, clearly differentiating between semantic segmentation and material segmentation.",
        "contenido_list_item5": "Finally, we will analyze specific advanced techniques for material segmentation, including concepts such as BRDF, specular and diffuse reflection, polarization, spectral analysis, and linear and non-linear spectral unmixing techniques.",
        "contenido_footer": "Throughout the session, practical activities will be included as appropriate.",
        "sesion_title": "Session Content",
        "sesion_presentacion_title": "PDF Presentation",
        "sesion_presentacion_description": "You can navigate through the presentation using the viewer controls.",
        "sesion_video_title": "Session Video"
    },
    "DiscordBubble": {
        "join": "Join our community!"
    },
    "AboutCard": {
        "view_details": "View Details"
    },
    "Navbar": {
        "home": "Home",
        "sessions": "Sessions",
        "gallery": "Gallery",
        "about_us": "About Us",
        "projects": "Projects",
        "discord": "Discord",
        "youtube": "YouTube",
        "instagram": "Instagram",
        "github": "GitHub",
        "wiki": "HoCV Wiki"
    },
    "EventContentCard": {
        "explore_session": "Explore Session"
    },
    "FixedPlugin": {
        "join_discord": "Join Discord"
    },
    "Footer": {
        "cta": "Join and boost your knowledge in Computer Vision",
        "registration_closed": "The registration date has ended",
        "made_by": "Made by"
    },
    "ProjectPage": {
        "back_to_session_12": "‚Üê Back to Session 12",
        "view_code": "View Code",
        "view_slides": "View Slides",
        "summary": "Summary"
    },
    "Sesion9": {
        "sidebar_introduccion": "Introduction and Objectives",
        "sidebar_lecturas": "Previous Resources",
        "sidebar_contenido": "Session Development",
        "sidebar_actividades": "Subsequent Activities",
        "sidebar_sesion": "Session Content",
        "hero_title": "Thermal Imaging",
        "hero_description": "In this session, the principles of thermal imaging will be explored, from the emission of radiation by black bodies to its application in fields such as science, medicine, engineering, and environmental observation. Participants will be able to familiarize themselves with the physical fundamentals and lay the groundwork for practical activities.",
        "introduccion_title": "Introduction and Objectives",
        "introduccion_description": "The objective of this session is to develop a comprehensive notion of the field of thermal imaging, covering from the physical phenomena involved to its main applications and characteristics.",
        "lecturas_title": "Resources and Previous Readings",
        "lecturas_description": "To make the most of this session, we recommend that you review the following resources:",
        "lecturas_link1": "Infrared Light Physics Experiments",
        "lecturas_link2": "What is Infrared",
        "lecturas_link3": "Spectrophotometry and Beer's Law",
        "lecturas_link4": "‚ÄúIntroduction to Thermal Infrared‚Äù Blog",
        "contenido_title": "Session Development",
        "contenido_description": "In accordance with the Hands-On methodology, this session will combine the exploration of theory with its practical application:",
        "contenido_list_item1": "Thermal imaging and applications: Real use cases, motivation, and examples that illustrate the value of this technology in various contexts.",
        "contenido_list_item2": "Light and radiation: Fundamental laws such as Kirchhoff's and Planck's, visualization of thermal radiation, and concepts of emissivity and attenuation.",
        "contenido_list_item3": "Thermal spectral imaging: Beer's law, atmospheric emission, spectral dependence of emissivity, and simulations.",
        "contenido_list_item4": "From physics to deep learning: Recent applications of computer vision to estimate physical parameters from thermal images.",
        "contenido_footer": "Throughout the session, practical activities will be included as appropriate.",
        "sesion_title": "Session Content",
        "sesion_presentacion_title": "PDF Presentation",
        "sesion_presentacion_description": "You can navigate through the presentation using the viewer controls.",
        "sesion_video_title": "Session Video"
    },
    "Sesion10": {
        "sidebar_introduccion": "Introduction and Objectives",
        "sidebar_lecturas": "Previous Resources",
        "sidebar_contenido": "Session Development",
        "sidebar_actividades": "Subsequent Activities",
        "sidebar_sesion": "Session Content",
        "hero_title": "Optimization",
        "hero_description": "In this session, the fundamentals of convex optimization will be explored, from its formal definition to its application in inverse problems and deep learning. We will see why it is so important to guarantee convexity, how to effectively solve these problems, and how to face ill-posed scenarios.",
        "introduccion_title": "Introduction and Objectives",
        "introduccion_description": "That participants acquire a solid understanding of what a convex optimization problem is, the techniques to solve it, examples of real applications, and how to address inverse and 'ill-posed' problems using optimization and neural networks.",
        "lecturas_title": "Resources and Previous Readings",
        "lecturas_description": "To make the most of this session, we recommend that you review the following resources:",
        "lecturas_link1": "Introduction to convex optimization",
        "lecturas_link2": "Convexity and The Principle of Duality",
        "lecturas_link3": "AI for emerging inverse problems in computational imaging by Shirin Jalali",
        "contenido_title": "Session Development",
        "contenido_description": "In accordance with the Hands-On methodology, this session will combine the exploration of theory with its practical application:",
        "contenido_list_item1": "We will begin by concisely defining what convex optimization is and why guaranteeing the convexity of a problem is key to obtaining unique and stable solutions.",
        "contenido_list_item2": "Then, we will offer an overview of the main families of resolution methods, both analytical and iterative, to understand their advantages and limitations.",
        "contenido_list_item3": "Next, we will present real applications in fields such as machine learning, computer vision, and engineering, illustrating with concrete examples the practical scope of convex optimization.",
        "contenido_list_item4": "Subsequently, we will carry out a practical activity in which the attendees will address a classic inverse problem using code, applying the concepts learned.",
        "contenido_list_item5": "Finally, we will analyze the challenges of ill-posed problems and discuss how the integration of neural networks can improve the stability and quality of solutions.",
        "contenido_footer": "Throughout the session, practical activities will be included as appropriate.",
        "sesion_title": "Session Content",
        "sesion_presentacion_title": "PDF Presentation",
        "sesion_presentacion_description": "You can navigate through the presentation using the viewer controls.",
        "sesion_video_title": "Session Video"
    },
    "Sesion12": {
        "title": "Select your project"
    },
    "Proyects": {
        "equipo1_title": "Team 1",
        "equipo1_abstract": "This project analyzes and compares vegetation cover in Bucaramanga and its main municipalities through image segmentation. We use the Grounding DINO and Segment Anything (SAM) models to identify and delineate vegetation areas in urban environments, in order to support studies on sustainability and green planning.",
        "equipo2_title": "Team 2",
        "equipo2_abstract": "This project aims to apply natural language processing (NLP) techniques and artificial intelligence models to analyze the content of publications from university groups on Facebook. Through web scraping, public publications from the group are collected and processed to discover patterns, emotions, frequent behaviors, among others.",
        "equipo3_title": "Team 3",
        "equipo3_abstract": "According to the most recent Annual World Air Quality Report from IQAir, no Colombian city meets the World Health Organization (WHO) standards, which shows an environmental crisis driven by industrial, agricultural and waste emissions. Faced with this panorama, we developed a remote methane detection system using a spectral linear filter applied to hyperspectral images from the EnMAP satellite. Our methodology integrates spectral preprocessing, precise alignment of absorption signatures and covariance analysis to generate segmentation maps that identify possible emission sources. The results were consistent with local emission reports, demonstrating the potential of the approach for the geospatial identification of gases. This work confirms the viability of using satellite images for environmental monitoring and opens the way to improvements through artificial intelligence, with a view to more precise, automated and scalable systems for emission control.",
        "equipo4_title": "Team 4",
        "equipo4_abstract": "This project aimed to create a synthetic dataset for Non-Line-of-Sight (NLoS) scenarios, composed of pairs of transient images (space-time volumes) and depth maps, generated using the Mitsuba 3 rendering engine. For this, 3D geometries in OBJ format were used, which were carefully preprocessed and configured for their correct integration into the simulation environment. In addition, data augmentation techniques were implemented in order to enrich the variability of the generated set. As a result, a complete and structured dataset was obtained, useful for research and model training tasks related to computer vision.",
        "equipo5_title": "Team 5",
        "equipo5_abstract": "This project proposes an unsupervised algorithm for depth estimation in endoscopy videos, using deep learning. An adaptation technique using Low-Rank Adaptation (LoRA) is applied to a disparity estimation model, allowing its specialization in the medical domain without the need for annotated data. The training is carried out on a set of endoscopy images, with the aim of obtaining precise depth maps that can assist in clinical and surgical tasks.",
        "equipo6_title": "Team 6",
        "equipo6_abstract": "We developed an anti-personnel mine detection system based on deep learning using aerial thermal images from the public dataset 'Dataset of Thermographic Images for the Detection of Buried Landmines'. Our methodology combines image preprocessing techniques and fine-tuning of state-of-the-art architectures such as ResNet, ConvNeXt, Vision Transformer (ViT) and Swin Transformer for the binary classification task (mine / no mine), achieving an accuracy of 99.23%, precision of 100%, sensitivity of 94.87% and specificity of 100%, surpassing the state of the art. Additionally, we carried out a manual annotation process of 360 images for the detection task and trained YOLOv11, obtaining a precision of 99.4%, sensitivity of 97.8% and a mAP@50 of 99.3%, establishing a solid baseline for localization tasks. This work highlights the potential of deep learning together with thermal images in critical humanitarian security tasks, opening the way towards automated and robust solutions in the removal of anti-personnel mines.",
        "equipo7_title": "Team 7",
        "equipo7_abstract": "The project proposes to develop a deblurring model (restoration of out-of-focus images) that uses depth maps as a structural guide and prioritization of regions, improving current methods based solely on RGB images. The research includes the study of depth of field (DoF) blur, the creation of a synthetic dataset with RGB images, depth maps and blurred versions, and the design of a neural network architecture that integrates this geometric information to recover details with greater precision in critical areas, followed by its training and evaluation.",
        "equipo8_title": "Team 8",
        "equipo8_abstract": "This project aims to analyze, georeference and visualize point clouds obtained using LiDAR (Light Detection and Ranging) technology. Through the processing of three-dimensional spatial data, it seeks to extract relevant information from the physical environment, facilitating the structural and geospatial interpretation of the terrain. The workflow includes reading and cleaning data in .bag format, correcting and transforming coordinates for proper georeferencing, and interactive visualization of the point cloud. This project is applicable to multiple areas, such as cartography, civil engineering, archeology, environment and urban planning.",
        "equipo9_title": "Team 9",
        "equipo9_abstract": "In this work we propose a methodology for the precise segmentation of objects in three-dimensional representations obtained through neural radiance fields (NeRF) networks. The segmentation of specific objects in NeRF scenes presents challenges due to the need to maintain consistency and precision in multiple 3D views. To address this problem, we effectively integrate the Segment Anything Model (SAM), allowing segmentations to be performed using textual indications or interactive points directly on the images. Our proposal was evaluated with two additional scenes from the Industrial University of Santander, each composed of 200 images, showing robust and coherent results in multiple perspectives. In addition, we incorporated the nerfstudio platform, facilitating user interaction and significantly improving the experience in three-dimensional visualization and segmentation."
    }
}