{
    "HomePage": {
      "title": "Hello world!",
      "about": "Go to the about page",
      "description": "Transforma tu visión del mundo: descubre el poder y las posibilidades ilimitadas de la visión por computadora",
      "learn_more": "Ver más"
    },
    "Hero": {
        "title": "Hands-on",
        "subtitle1": "omputer",
        "subtitle2": "ision",
        "learn_more": "Ver más"
    },
    "EventContent": {
        "title": "Cronograma del Semillero",
        "session1_title": "Sesión 1",
        "session1_subject": "Sesión 1: Pilot",
        "session1_des": "Introducción al semillero.",
        "session2_title": "Sesión 2",
        "session2_subject": "Sesión 2: De fotones a pixeles",
        "session2_des": "Generalidades sobre la adquisición y procesamiento digital de imágenes",
        "session3_title": "Sesión 3",
        "session3_subject": "Sesión 3: Deep Learning",
        "session3_des": "Despierta el poder de la inteligencia artificial en la visión por computadora",
        "session4_title": "Sesión 4",
        "session4_subject": "Sesión 4: Imágenes Espectrales",
        "session4_des": "Conoce los secretos que hay mas allá de una imagen de color.",
        "session5_title": "Sesión 5",
        "session5_subject": "Sesión 5: Estimación pasiva de la profundidad",
        "session5_des": "Explora las técnicas de estimación de profundidad sin fuentes externas",
        "session6_title": "Sesión 6",
        "session6_subject": "Sesión 6: Estimación activa de la profundidad",
        "session6_des": "Extrayendo profundidad con precisión milimétrica a partir de la luz.",
        "session7_title": "Sesión 7",
        "session7_subject": "Sesión 7: Asignación de proyectos",
        "session7_des": "Rétate a ti mismo 🔥🔥",
        "session8_title": "Sesión 8",
        "session8_subject": "Sesión 8: Segmentación",
        "session8_des": "Delineando el mundo digital a través de píxeles clasificados meticulosamente",
        "session9_title": "Sesión 9",
        "session9_subject": "Sesión 9: Imágenes térmicas",
        "session9_des": "El mundo visto a través del calor",
        "session10_title": "Sesión 10",
        "session10_subject": "Sesión 10: Optimización Convexa",
        "session10_des": "Optimizando el mundo con matemáticas",
        "session11_title": "Sesión 11",
        "session11_subject": "Sesión 11: NLP",
        "session11_des": "Aprendiendo a hablar con las máquinas",
        "session12_title": "Sesión 12",
        "session12_subject": "Sesión 12: Proyectos finales",
        "session12_des": "Desafía tus habilidades 🚀 🚀"
    },
    "Faq": {
        "directed_by": "Dirigido por",
        "name": "Hoover Fabian Rueda Chacón",
        "bio": "Ingeniero de Sistemas e Informática, con maestría y doctorado en Ingeniería Eléctrica y Computación. Realizó su formación en Colombia y EE. UU., siendo Asociado Postdoctoral en la Universidad de Boston. Sus áreas de investigación incluyen procesamiento de imágenes, algoritmos, óptica computacional y optimización numérica."
    },
    "Layout": {
        "title": "Hands-On Computer Vision",
        "description": "Únete a nosotros en el Semillero Hands-on Computer Vision y sumérgete en una experiencia única que fusiona la teoría con la práctica en el fascinante mundo de la visión por computadora. Nos enfocaremos en temas avanzados como Fotografía computacional, Aprendizaje profundo, Imágenes térmicas, Imágenes espectrales, Estimación de la profundidad y más"
    },
    "LumaEmbed": {
        "loading": "Cargando evento..."
    },
    "ProjectsCarousel": {
        "title": "🏆 Proyectos de Grado 🏆",
        "project1_title": "Segmentación De Materiales A Partir De Imágenes RGB  Usando Arquitecturas De Transformadores De Visión E Integración De Información Multiespectral",
        "project2_title": "Simulación De Una Cámara Contadora De Fotones Para La Adquisición De Imágenes Transitorias En Escenarios Sin Línea De Visión",
        "project3_title": "Estimación de la velocidad de navegación segura para vehículos autónomos utilizando técnicas de visión por computadora",
        "project4_title": "Fusión de imágenes de profundidad obtenida con sistemas LiDAR y de Estereovisión por medio de técnicas de aprendizaje profundo",
        "view_pdf": "Ver PDF",
        "slides": "Slides",
        "code": "Código"
    },
    "SponsoredBy": {
        "title": "Áreas de Investigación",
        "area1_title": "Imágenes sin visibilidad directa",
        "area1_description": "Mira a través de las paredes: tecnología para ver más allá de los obstáculos.",
        "area2_title": "Estimación de la profundidad",
        "area2_description": "Profundiza en el mundo 3D: algoritmos que miden distancias con precisión.",
        "area3_title": "NLP",
        "area3_description": "Comunícate con las máquinas: inteligencia que entiende el lenguaje humano.",
        "area4_title": "Segmentación de materiales",
        "area4_description": "Segmenta a con alta precisión: identificación meticulosa de materiales en imágenes.",
        "area5_title": "Imágenes espectrales",
        "area5_description": "Más allá del RGB: captura el espectro completo de la luz.",
        "area6_title": "Imágenes térmicas",
        "area6_description": "Visualiza a través del calor: tecnología que revela lo invisible al ojo humano."
    },
    "Galeria": {
        "title1": "En 2024, exploramos y profundizamos en la visión por computadora. Este es un resumen visual de las sesiones que inspiraron el aprendizaje y la innovación.",
        "title2": "Nos apasiona compartir los últimos avances en Deep Learning. Estas son algunas imágenes de nuestras sesiones de estudio y de nuestra participación en U24Fest.",
        "title3": "En HoCV, creamos un espacio para compartir, colaborar y crecer juntos como equipo, fortaleciendo la comunidad y el aprendizaje colectivo."
    },
    "Nosotros": {
        "title": "Construyendo el futuro de la Visión por Computadora",
        "mission_title": "Nuestra Misión",
        "mission_description": "Impulsamos la innovación formando la próxima generación de expertos en computer vision a través de experiencias investigativas y colaborativas.",
        "professors_title": "Profesores",
        "professor1_name": "Hoover Rueda-Chacón",
        "professor1_role": "Director del Semillero",
        "masters_students_title": "Estudiantes de Maestría",
        "masters_student1_name": "Fabian Pérez",
        "masters_student1_role": "Msc(s) Computer Science",
        "masters_student2_name": "Julian Leon",
        "masters_student2_role": "Msc(s) Applied Mathematics",
        "undergraduate_students_title": "Estudiantes de Pregrado",
        "undergraduate_student1_name": "Cristian Rey",
        "undergraduate_student1_role": "Estudiante de Ingeniería de Sistemas",
        "undergraduate_student2_name": "Miguel Ángel",
        "undergraduate_student2_role": "Estudiante de Ingeniería de Sistemas",
        "undergraduate_student3_name": "Ramiro Avila",
        "undergraduate_student3_role": "Estudiante de Ingeniería de Sistemas",
        "undergraduate_student4_name": "Henry Mantilla",
        "undergraduate_student4_role": "Estudiante de Ingeniería de Sistemas",
        "undergraduate_student5_name": "Paula Uzcategui",
        "undergraduate_student5_role": "Estudiante de Ingeniería Sistemas y Biologia",
        "undergraduate_student6_name": "Guillermo Pinto",
        "undergraduate_student6_role": "Estudiante de Ingeniería de Sistemas",
        "undergraduate_student7_name": "Sebastian Solano",
        "undergraduate_student7_role": "Estudiante de Ingeniería Electronica",
        "undergraduate_student8_name": "Brayan Quintero",
        "undergraduate_student8_role": "Estudiante de Ingeniería Sistemas",
        "undergraduate_student9_name": "Andrea Parra",
        "undergraduate_student9_role": "Estudiante de Ingeniería Sistemas",
        "undergraduate_student10_name": "Dana Villamizar",
        "undergraduate_student10_role": "Estudiante de Ingeniería Sistemas",
        "undergraduate_student11_name": "Jorge Garcia",
        "undergraduate_student11_role": "Estudiante de Ingeniería Sistemas",
        "undergraduate_student12_name": "Juan Toloza",
        "undergraduate_student12_role": "Estudiante de Ingeniería Sistemas",
        "undergraduate_student13_name": "Sneider Sánchez",
        "undergraduate_student13_role": "Estudiante de Ingeniería Sistemas",
        "undergraduate_student14_name": "Juan Calderon",
        "undergraduate_student14_role": "Estudiante de Ingeniería Sistemas",
        "undergraduate_student15_name": "Valentina Pérez",
        "undergraduate_student15_role": "Estudiante de Ingeniería Sistemas",
        "undergraduate_student16_name": "Miguel Pimiento",
        "undergraduate_student16_role": "Estudiante de Ingeniería Sistemas",
        "undergraduate_student17_name": "César Vanegas",
        "undergraduate_student17_role": "Estudiante de Ingeniería Sistemas"
    },
    "Sesiones": {
        "session1_title": "Pilot",
        "session1_location": "Introducción",
        "session1_description": "Introducción al semillero",
        "session2_title": "De fotones a pixeles",
        "session2_location": "Fundamentos",
        "session2_description": "Generalidades sobre la adquisición y procesamiento digital de imágenes",
        "session3_title": "Deep Learning",
        "session3_location": "IA & CV",
        "session3_description": "Despierta el poder de la inteligencia artificial en la visión por computadora",
        "session4_title": "Imágenes Espectrales",
        "session4_location": "Procesamiento",
        "session4_description": "Conoce los secretos que hay mas allá de una imagen de color.",
        "session5_title": "Estimación pasiva de la profundidad",
        "session5_location": "3D Vision",
        "session5_description": "Explora las técnicas de estimación de profundidad sin fuentes externas",
        "session6_title": "Estimación activa de la profundidad",
        "session6_location": "3D Vision",
        "session6_description": "Extrayendo profundidad con precisión milimétrica a partir de la luz.",
        "session7_title": "Asignación de proyectos",
        "session7_location": "Proyectos",
        "session7_description": "Rétate a ti mismo 🔥🔥",
        "session8_title": "Segmentación",
        "session8_location": "Procesamiento",
        "session8_description": "Delineando el mundo digital a través de píxeles clasificados meticulosamente",
        "session9_title": "Imágenes térmicas",
        "session9_location": "Procesamiento",
        "session9_description": "El mundo visto a través del calor",
        "session10_title": "Optimización Convexa",
        "session10_location": "Matemáticas",
        "session10_des": "Optimizando el mundo con matemáticas",
        "session11_title": "NLP",
        "session11_location": "IA",
        "session11_des": "Aprendiendo a hablar con las máquinas",
        "session12_title": "Proyectos finales",
        "session12_location": "Proyectos",
        "session12_des": "Desafía tus habilidades 🚀 🚀"
    },
    "Sesion1": {
        "sidebar_introduccion": "Introducción y Objetivos",
        "sidebar_lecturas": "Recursos Previos",
        "sidebar_contenido": "Desarrollo de la Sesión",
        "sidebar_actividades": "Actividades Posteriores",
        "sidebar_sesion": "Contenido de la Sesión",
        "hero_title": "Pilot: Introducción al Semillero",
        "hero_description": "Bienvenido a la primera sesión del semillero. Aquí sentamos las bases para explorar el fascinante mundo de la visión por computadora y definir los objetivos que nos acompañan en este emocionante camino.",
        "introduccion_title": "Introducción y Objetivos",
        "introduccion_description": "En esta sesión introductoria, presentamos el contexto y los objetivos del semillero. Exploraremos la historia, la importancia y las aplicaciones actuales de la visión por computadora, sentando las bases para profundizar en conceptos más avanzados.",
        "lecturas_title": "Recursos y Lecturas Previas",
        "lecturas_description": "Antes de asistir a la sesión, te recomendamos revisar los siguientes recursos para familiarizarte con los conceptos básicos:",
        "lecturas_link1": "\"How we're teaching computers to understand pictures\"",
        "lecturas_link2": "¿Qué es la visión artificial?",
        "contenido_title": "Desarrollo de la Sesión",
        "contenido_description1": "Durante esta sesión, combinamos teoría y práctica. A través de presentaciones y demostraciones en vivo, abordamos temas como la adquisición y procesamiento de imágenes, fundamentos de Deep Learning y técnicas de análisis visual. Todo se desarrolla de manera dinámica y participativa.",
        "contenido_description2": "Fomentamos la interacción y el debate, permitiéndote experimentar con ejemplos reales y sentar las bases para proyectos futuros.",
        "actividades_title": "Actividades y Tareas Posteriores",
        "actividades_description1": "Al concluir la sesión, se te asignarán actividades prácticas para consolidar los conocimientos adquiridos. Estas tareas te permitirán experimentar de manera autónoma y preparar el terreno para los siguientes módulos.",
        "actividades_description2": "Además, promoveremos el intercambio de ideas en grupo, permitiendo la discusión y resolución de dudas en un ambiente colaborativo.",
        "sesion_title": "Contenido de la Sesión",
        "sesion_presentacion_title": "Presentación en PDF",
        "sesion_presentacion_description": "Puedes navegar por la presentación usando los controles del visor.",
        "sesion_video_title": "Video de la sesión"
    },
    "Sesion2": {
        "sidebar_introduccion": "Introducción y Objetivos",
        "sidebar_lecturas": "Recursos y Lecturas Previas",
        "sidebar_contenido": "Desarrollo de la Sesión",
        "sidebar_actividades": "Actividades y Tareas Posteriores",
        "sidebar_sesion": "Contenido de la Sesión",
        "hero_title": "De Fotones a Píxeles",
        "hero_description": "En esta sesión, exploramos la transición desde la luz hasta la imagen digital. Nos sumergiremos en los principios fundamentales de la formación de imágenes, desde los conceptos ópticos hasta el procesamiento digital, estableciendo las bases esenciales para comprender cómo las cámaras capturan y procesan la luz.",
        "introduccion_title": "Introducción y Objetivos",
        "introduccion_description": "El objetivo de esta sesión es comprender los principios físicos y matemáticos que permiten la captura de imágenes. Exploraremos la relación entre la óptica, los sensores y los algoritmos que convierten la luz en datos procesables. Esta sesión servirá como base para entender técnicas avanzadas de análisis y manipulación de imágenes en futuras sesiones.",
        "lecturas_title": "Recursos y Lecturas Previas",
        "lecturas_description": "Antes de asistir a la sesión, te recomendamos revisar los siguientes recursos para familiarizarte con los conceptos básicos:",
        "lecturas_link1": "TED-EdLight waves, visible and invisible",
        "lecturas_link2": "Basics Explained, H3VtuxDigital vs Analog. What's the Difference? Why Does it Matter...",
        "lecturas_link3": "TED-EdCamera or eye: Which sees better? - Michael Mauser",
        "lecturas_link4": "Understanding digital camera sensors",
        "lecturas_link5": "Color image Demosaicing",
        "lecturas_link6": "How to Turn a Room into a Camera Obscura",
        "lecturas_link7": "Vermeer and the Camera Obscura: Part I",
        "contenido_title": "Desarrollo de la Sesión",
        "contenido_description": "En esta sesión, combinamos teoría y práctica para explorar los siguientes temas:",
        "contenido_list_item1": "Formación de imágenes: Explicación del concepto de la cámara oscura, la propagación de la luz y la relación entre el campo de visión (FOV), el ángulo de visión (AOV) y la profundidad de campo (DoF).",
        "contenido_list_item2": "El triángulo de la exposición: Análisis de la velocidad de obturación (shutter speed), la apertura del diafragma y la sensibilidad ISO.",
        "contenido_list_item3": "Imágenes digitales: Transformación de un dominio continuo a uno digital, profundidad de bits y tipos de imágenes (binarias, escala de grises, color, espectrales, video, etc.).",
        "contenido_list_item4": "Sensores ópticos: Anatomía de un sensor, diferencias entre CMOS y CCD, balance de blancos, demosaicking y ruido en la imagen.",
        "contenido_list_item5": "Pipeline de procesamiento de imágenes: Etapas del procesamiento desde la captura hasta la imagen final.",
        "contenido_list_item6": "Transformaciones de imágenes: Corrección de gamma, ecualización de histograma, filtrado lineal y convolución 2D.",
        "contenido_footer": "La sesión será participativa e incluirá demostraciones prácticas para reforzar los conceptos teóricos.",
        "actividades_title": "Actividades y Tareas Posteriores",
        "actividades_description": "Al finalizar la sesión, se asignarán ejercicios prácticos para consolidar los conocimientos adquiridos. Estas actividades incluirán:",
        "actividades_list_item1": "Experimentación con una cámara oscura casera.",
        "actividades_list_item2": "Implementación básica de corrección de gamma y ecualización de histograma.",
        "sesion_title": "Contenido de la Sesión",
        "sesion_presentacion_title": "Presentación en PDF",
        "sesion_presentacion_description": "Puedes navegar por la presentación usando los controles del visor.",
        "sesion_video_title": "Video de la sesión"
    },
    "Sesion3": {
        "sidebar_introduccion": "Introducción y Objetivos",
        "sidebar_lecturas": "Recursos y Lecturas Previos",
        "sidebar_contenido": "Desarrollo de la Sesión",
        "sidebar_actividades": "Actividades y Tareas Posteriores",
        "sidebar_sesion": "Contenido de la Sesión",
        "hero_title": "Deep Learning",
        "hero_description": "En esta sesión nos sumergimos en el fascinante mundo del Deep Learning, explorando desde sus principios fundamentales hasta sus aplicaciones más recientes. Desde la construcción de un perceptrón multicapa desde cero hasta el análisis de redes neuronales convolucionales, descubriremos cómo estas tecnologías están transformando nuestra interacción con el mundo visual.",
        "introduccion_title": "Introducción y Objetivos",
        "introduccion_description": "El objetivo principal de esta sesión es comprender los fundamentos del Deep Learning y su aplicación en visión por computadora. Exploraremos la evolución histórica de esta tecnología, comprenderemos sus principios matemáticos básicos, y analizaremos hacia dónde se dirige el campo. Al finalizar, serás capaz de entender cómo se construye un perceptrón multicapa desde cero, reconocer el funcionamiento de las redes neuronales convolucionales, y visualizar las tendencias actuales y futuras del Deep Learning.",
        "lecturas_title": "Recursos y Lecturas Previas",
        "lecturas_description": "Para aprovechar al máximo esta sesión, te recomendamos revisar los siguientes recursos:",
        "lecturas_link1": "Charla de Andrej Karpathy: Building Generative Models",
        "lecturas_link2": "Serie 3Blue1Brown: Neural Networks",
        "lecturas_link3": "TensorFlow Playground - Experimentación interactiva",
        "contenido_title": "Desarrollo de la Sesión",
        "contenido_description": "Durante esta sesión, exploraremos:",
        "contenido_list_item1": "¿Qué es el Deep Learning? Definición, historia breve y diferencias con otras formas de aprendizaje automático.",
        "contenido_list_item2": "Aplicaciones prácticas: Casos de uso en la industria y la investigación, con énfasis en visión por computadora.",
        "contenido_list_item3": "Fundamentos matemáticos: Comprensión de los principios básicos que permiten el funcionamiento de las redes neuronales.",
        "contenido_list_item4": "No-linealidad: Importancia de las funciones de activación y cómo permiten modelar relaciones complejas.",
        "contenido_list_item5": "Funciones de coste (Losses): Medición del error y optimización del rendimiento de los modelos.",
        "contenido_list_item6": "Backpropagation y SGD: Algoritmos fundamentales para el entrenamiento de redes neuronales.",
        "contenido_list_item7": "Interpretación de pesos y sesgos: Comprender qué representan realmente los parámetros de una red.",
        "contenido_list_item8": "Redes neuronales convolucionales: Arquitectura especializada para el procesamiento de imágenes.",
        "contenido_list_item9": "Tendencias actuales: Hacia dónde se dirige el campo del Deep Learning y qué podemos esperar en el futuro.",
        "contenido_footer": "Implementaremos un perceptrón multicapa desde cero para entender profundamente su funcionamiento interno, y analizaremos ejemplos prácticos para reforzar los conceptos teóricos.",
        "sesion_title": "Contenido de la Sesión",
        "sesion_presentacion_title": "Presentación en PDF",
        "sesion_presentacion_description": "Puedes navegar por la presentación usando los controles del visor.",
        "sesion_video_title": "Video de la sesión"
    },
    "Sesion4": {
        "sidebar_introduccion": "Introducción y Objetivos",
        "sidebar_lecturas": "Recursos y Lecturas Previas",
        "sidebar_contenido": "Desarrollo de la Sesión",
        "sidebar_actividades": "Actividades y Tareas Posteriores",
        "hero_title": "Imágenes Espectrales",
        "hero_description": "En esta sesión se presentan los conceptos fundamentales sobre las imágenes espectrales. Para construir una definición integral de este campo, se explorarán temas como el espectro electromagnético, el sensado remoto y la firma espectral. Además, se abordarán sus principales aplicaciones y los distintos métodos de adquisición. Finalmente, dado que la captura de estas imágenes en un contexto real involucra principios ópticos, se analizarán fenómenos como la dispersión y la difracción de la luz.",
        "introduccion_title": "Introducción y Objetivos",
        "introduccion_description": "El objetivo de esta sesión es desarrollar una noción integral del campo de las imágenes espectrales, abarcando desde los fenómenos físicos involucrados hasta las principales aplicaciones y características de este tipo de adquisiciones.",
        "lecturas_title": "Recursos y Lecturas Previas",
        "lecturas_description": "Para aprovechar al máximo esta sesión, te recomendamos revisar los siguientes recursos:",
        "lecturas_link1": "Mapping the Invisible: Introduction to Spectral Remote Sensing",
        "lecturas_link2": "Hyperspectral Imaging - eoPortal",
        "lecturas_link3": "Getting Started with Hyperspectral Image Processing",
        "lecturas_link4": "Hyperspectral image analysis with Python made easy",
        "contenido_title": "Desarrollo de la Sesión",
        "contenido_description": "De acuerdo con la metodología Hands-On, esta sesión combinará la exploración de la teoría de mano con su aplicación práctica:",
        "contenido_list_item1": "Introducción a las imágenes espectrales: Qué son, cómo se clasifican, su relación con el espectro electromagnético, su adquisición mediante sensado remoto y el concepto de firma espectral.",
        "contenido_list_item2": "Aplicaciones: Clasificación de materiales, detección de características no visibles a simple vista, monitoreo mediante satélites, entre otras.",
        "contenido_list_item3": "Métodos de adquisición: Pixel a pixel, línea a línea, banda a banda y todo en uno.",
        "contenido_list_item4": "Fenómenos físicos: Dispersión y difracción, métodos avanzados de adquisición",
        "contenido_footer": "A lo largo de la sesión, se incluirán actividades prácticas según corresponda.",
        "sesion_title": "Contenido de la Sesión",
        "sesion_presentacion_title": "Presentación en PDF",
        "sesion_presentacion_description": "Puedes navegar por la presentación usando los controles del visor.",
        "sesion_video_title": "Video de la sesión"
    },
    "Sesion5": {
        "sidebar_introduccion": "Introducción y Objetivos",
        "sidebar_lecturas": "Recursos y Lecturas Previas",
        "sidebar_contenido": "Desarrollo de la Sesión",
        "sidebar_actividades": "Actividades y Tareas Posteriores",
        "hero_title": "Estimación pasiva de la profundidad",
        "hero_description": "En esta sesión se exploran los principios fundamentales de la estimación pasiva de la profundidad. Se analizará cómo los sistemas visuales extraen información tridimensional a partir de imágenes, abarcando conceptos clave como la percepción de profundidad y la disparidad. Se hará un énfasis especial en técnicas como la visión estéreo, detallando los pasos necesarios para la reconstrucción 3D de la escena. Además, se incluirán enfoques modernos basados en métodos de aprendizaje profundo, explorando sus aplicaciones en áreas como la robótica y los vehículos autónomos.",
        "introduccion_title": "Introducción y Objetivos",
        "introduccion_description": "El objetivo de esta sesión es comprender los principios detrás de la estimación de la profundidad, explorando el proceso completo necesario para transformar imágenes 2D en representaciones 3D. Se detallarán las técnicas y pasos involucrados, desde la captura de las imágenes hasta la reconstrucción tridimensional precisa.",
        "lecturas_title": "Recursos y Lecturas Previas",
        "lecturas_description": "Para aprovechar al máximo esta sesión, te recomendamos revisar los siguientes recursos:",
        "lecturas_link1": "Depth Perception",
        "lecturas_link2": "Stereo Vision: Depth Estimation between object and camera",
        "lecturas_link3": "The State of the Art of Depth Estimation from Single Images",
        "lecturas_link4": "Disparity and Depth Estimation From Stereo Camera",
        "lecturas_link5": "Simple Stereo | Camera Calibration",
        "lecturas_link6": "Structure from Motion Problem | Structure from Motion",
        "contenido_title": "Desarrollo de la Sesión",
        "contenido_description": "De acuerdo con la metodología Hands-On, esta sesión combinará la exploración de la teoría de mano con su aplicación práctica:",
        "contenido_list_item1": "Introducción a la percepción de profundidad: Qué es la profundidad, cómo la perciben los seres humanos a través de sus ojos, y las aplicaciones de este proceso en visión artificial.",
        "contenido_list_item2": "Técnicas de estimación de profundidad: Métodos pasivos (como la visión estéreo) y métodos activos (como el LIDAR), sus ventajas y limitaciones.",
        "contenido_list_item3": "Visión estéreo: Conceptos clave de percepción, disparidad, profundidad, geometría de proyección, rectificación, y la técnica de Structure from Motion (SfM) aplicada a través del aprendizaje profundo.",
        "contenido_footer": "A lo largo de la sesión, se incluirán actividades prácticas según corresponda.",
        "sesion_title": "Contenido de la Sesión",
        "sesion_presentacion_title": "Presentación en PDF",
        "sesion_presentacion_description": "Puedes navegar por la presentación usando los controles del visor.",
        "sesion_video_title": "Video de la sesión"
    },
    "Sesion6": {
        "sidebar_introduccion": "Introducción y Objetivos",
        "sidebar_lecturas": "Recursos y Lecturas Previas",
        "sidebar_contenido": "Desarrollo de la Sesión",
        "sidebar_actividades": "Actividades y Tareas Posteriores",
        "hero_title": "Estimación activa de la profundidad",
        "hero_description": "En esta sesión, nos adentraremos en los fundamentos de la estimación activa de la profundidad, una técnica innovadora que aprovecha las ventajas de la detección de la luz en movimiento para estimar con alta precisión la distancia a la que se encuentra un objeto en una escena. Este enfoque permite obtener información tridimensional de una manera mucho más precisa que las técnicas tradicionales. Además, analizaremos las increíbles aplicaciones de este enfoque en diversas áreas, desde la robótica hasta los vehiculos autonomos y la visualización de objetos que se encuentran ocultos.",
        "introduccion_title": "Introducción y Objetivos",
        "introduccion_description": "El objetivo principal de esta sesión es proporcionar una comprensión integral de la estimación activa de la profundidad y las tecnologías que la respaldan, entendiendo cómo la luz nos permite obtener mediciones precisas de una escena.",
        "lecturas_title": "Recursos y Lecturas Previas",
        "lecturas_description": "Para aprovechar al máximo esta sesión, te recomendamos revisar los siguientes recursos:",
        "lecturas_link1": "How Structured Light works",
        "lecturas_link2": "What is TOF (Time of Flight) & How Does it Work?",
        "lecturas_link3": "ToF (Time of Flight) Technology - Industrial Use",
        "lecturas_link4": "What Is Time-of-Flight? – Vision Campus",
        "contenido_title": "Desarrollo de la Sesión",
        "contenido_description": "De acuerdo con la metodología Hands-On, esta sesión combinará la exploración de la teoría de mano con su aplicación práctica:",
        "contenido_list_item1": "Métodos de estimación de la profundidad: Breve recordatorio de la sesión anterior, diferencia entre los métodos pasivos vs métodos activos de estimación de la profundidad y las características clave de cada uno.",
        "contenido_list_item2": "Luz estructurada: En que consiste el método de luz estructurada, cómo este enfoque nos permite estimar la profundidad de un objeto proyectando patrones de luz y exploraremos las principales aplicaciones que aprovechan esta tecnología.",
        "contenido_list_item3": "Tiempo de vuelo de la luz: Definición de tiempo de vuelo y diferencias entre el tiempo de vuelo indirecto (iToF) y el tiempo de vuelo directo (dToF). Además, veremos qué sensores están capacitados para medir la luz en movimiento y cómo se utilizan para obtener mediciones precisas de profundidad.",
        "contenido_list_item4": "Aplicaciones interesantes de medir la luz en movimiento. Como podemos reconstruir escenas con ayuda de la luz.",
        "contenido_footer": "A lo largo de la sesión, se incluirán actividades prácticas según corresponda.",
        "sesion_title": "Contenido de la Sesión",
        "sesion_presentacion_title": "Presentación en PDF",
        "sesion_presentacion_description": "Puedes navegar por la presentación usando los controles del visor.",
        "sesion_video_title": "Video de la sesión"
    },
    "Sesion7": {
        "sidebar_tabla": "Tabla de Proyectos",
        "sidebar_diapositivas": "Diapositivas de proyectos",
        "hero_title": "Asignación de proyectos",
        "hero_description": "En esta sesión especial del Semillero, hemos seleccionado proyectos finales innovadores que pondrán a prueba tus habilidades y ampliarán tus conocimientos en el área de visión por computadora.",
        "tabla_title": "Tabla de proyectos",
        "tabla_description": "En la siguiente tabla podrás consultar los miembros de cada grupo y los proyectos que les han sido asignados.",
        "tabla_header_equipo": "Equipo",
        "tabla_header_integrantes": "Integrantes",
        "tabla_header_tema": "Tema",
        "tabla_header_area": "Área",
        "equipo1_integrantes": ["Miguel Ayala", "Daniel Naranjo", "Miguel Jaimes"],
        "equipo1_tema": "Finetuning de CLIP con descripciones de imágenes para tarea de clasificación",
        "equipo1_grupo": "NLP",
        "equipo2_integrantes": ["Roger Hernandez", "Alejandro Moreno", "Christian Orduz"],
        "equipo2_tema": "Análisis de sentimientos y toxicidad en las redes sociales de la comunidad universitaria",
        "equipo2_grupo": "NLP",
        "equipo3_integrantes": ["Juan Jaimes", "Santiago Camargo", "Cristian Tristancho"],
        "equipo3_tema": "Segment local object in 3D with Neural Radiance Fields",
        "equipo3_grupo": "Segmentation",
        "equipo4_integrantes": ["Johan Sebastian", "Nicolas Rivera", "Mateo Delgado"],
        "equipo4_tema": "Detección y comparación de áreas verdes urbanas en ciudades colombianas mediante segmentación semántica de imágenes satelitales",
        "equipo4_grupo": "Segmentation",
        "equipo5_integrantes": ["Maria L. Rodriguez", "Juan F. Serrano", "Juan Jose Ardila"],
        "equipo5_tema": "Detección de fugas de gas con imágenes infrarrojas",
        "equipo5_grupo": "Thermal",
        "equipo6_integrantes": ["Jeison Guarguati", "Diego Rodriguez", "Jose Quintero"],
        "equipo6_tema": "Detección de minas antipersona en el Valle del Cauca",
        "equipo6_grupo": "Thermal",
        "equipo7_integrantes": ["Marian Becerra", "Andres Conde", "Jair Marquilla"],
        "equipo7_tema": "Generación de dataset NLoS usando técnicas de renderizado transitorio",
        "equipo7_grupo": "NLOS",
        "equipo8_integrantes": ["Juan Arias Sarabia", "Samuel Benilla", "Willianngel Ollevedo"],
        "equipo8_tema": "Análisis, georreferenciación y visualización de nubes de puntos LiDAR mediante técnicas de SLAM",
        "equipo8_grupo": "NLOS",
        "equipo9_integrantes": ["Oscar Carreño", "David Anaya", "Juan Vanegas"],
        "equipo9_tema": "Algoritmo no supervisado para la estimación de profundidad en videos de endoscopia",
        "equipo9_grupo": "Depth",
        "equipo10_integrantes": ["Oscar Ortega", "Samuel Traslaviña", "Jeferson Acevedo"],
        "equipo10_tema": "Sharpening de imagen utilizando información de depth maps",
        "equipo10_grupo": "Depth",
        "diapositivas_title": "Presentación en PDF",
        "diapositivas_description": "Puedes navegar por la presentación usando los controles del visor."
    },
    "Sesion8": {
        "sidebar_introduccion": "Introducción y Objetivos",
        "sidebar_lecturas": "Recursos y Lecturas Previas",
        "sidebar_contenido": "Desarrollo de la Sesión",
        "sidebar_actividades": "Actividades y Tareas Posteriores",
        "hero_title": "Segmentación de Imágenes",
        "hero_description": "En esta sesión, exploraremos los fundamentos y técnicas avanzadas de segmentación de imágenes, una herramienta fundamental en visión artificial que permite clasificar píxeles en regiones destacadas dentro de una escena. Entenderemos cómo diferentes técnicas, desde métodos tradicionales hasta avanzados basados en aprendizaje profundo, pueden utilizarse para interpretar el contenido visual de manera precisa y eficaz.",
        "introduccion_title": "Introducción y Objetivos",
        "introduccion_description": "El objetivo principal de esta sesión es proporcionar una comprensión integral sobre qué es la segmentación, cómo funciona, sus aplicaciones y las diversas técnicas que permiten identificar regiones significativas en imágenes digitales, destacando la importancia del contexto en la clasificación precisa de píxeles.",
        "lecturas_title": "Recursos y Lecturas Previas",
        "lecturas_description": "Para aprovechar al máximo esta sesión, te recomendamos revisar los siguientes recursos:",
        "lecturas_link1": "Principios de la Psicología Gestalt aplicados a percepción visual.",
        "lecturas_link2": "Introducción básica a algoritmos de clustering.",
        "lecturas_link3": "Técnicas básicas de aprendizaje profundo para visión artificial.",
        "contenido_title": "Desarrollo de la Sesión",
        "contenido_description": "De acuerdo con la metodología Hands-On, esta sesión combinará la exploración de la teoría de mano con su aplicación práctica:",
        "contenido_list_item1": "Comenzaremos definiendo la segmentación como la clasificación de píxeles en regiones coherentes, aplicando los principios Gestalt como proximidad, similaridad y simetría.",
        "contenido_list_item2": "Luego exploraremos diversas aplicaciones de la segmentación en áreas como la visión robótica, conducción autónoma y análisis médico, enfatizando la importancia del contexto visual en clasificaciones precisas.",
        "contenido_list_item3": "A continuación, abordaremos técnicas clásicas de segmentación como umbralización, clustering, mean-shift, SLIC y segmentación basada en grafos.",
        "contenido_list_item4": "Posteriormente, profundizaremos en la integración de métodos avanzados mediante redes neuronales convolucionales, diferenciando claramente entre segmentación semántica y segmentación de materiales.",
        "contenido_list_item5": "Finalmente, analizaremos técnicas avanzadas específicas para la segmentación de materiales, incluyendo conceptos como la BRDF, reflexión especular y difusa, polarización, análisis espectral y técnicas de desmezclado espectral lineal y no lineal.",
        "contenido_footer": "A lo largo de la sesión, se incluirán actividades prácticas según corresponda.",
        "sesion_title": "Contenido de la Sesión",
        "sesion_presentacion_title": "Presentación en PDF",
        "sesion_presentacion_description": "Puedes navegar por la presentación usando los controles del visor.",
        "sesion_video_title": "Video de la sesión"
    },
    "DiscordBubble": {
        "join": "¡Únete a nuestra comunidad!"
    },
    "AboutCard": {
        "view_details": "Ver Detalles"
    },
    "Navbar": {
        "home": "Inicio",
        "sessions": "Sesiones",
        "gallery": "Galería",
        "about_us": "Nosotros",
        "projects": "Proyectos",
        "discord": "Discord",
        "youtube": "YouTube",
        "instagram": "Instagram",
        "github": "GitHub",
        "wiki": "HoCV Wiki"
    },
    "EventContentCard": {
        "explore_session": "Explorar Sesión"
    },
    "FixedPlugin": {
        "join_discord": "Únete a Discord"
    },
    "Footer": {
        "cta": "Únete y potencia tus conocimientos en Visión por Computadora",
        "registration_closed": "La fecha de inscripción ha finalizado",
        "made_by": "Hecho por"
    },
    "ProjectPage": {
        "back_to_session_12": "← Volver a Sesión 12",
        "view_code": "Ver Código",
        "view_slides": "Ver Slides",
        "summary": "Resumen"
    },
    "Sesion9": {
        "sidebar_introduccion": "Introducción y Objetivos",
        "sidebar_lecturas": "Recursos y Lecturas Previas",
        "sidebar_contenido": "Desarrollo de la Sesión",
        "sidebar_actividades": "Actividades y Tareas Posteriores",
        "sidebar_sesion": "Contenido de la Sesión",
        "hero_title": "Imágenes térmicas",
        "hero_description": "En esta sesión se explorarán los principios de las imágenes térmicas, desde la emisión de radiación por cuerpos negros hasta su aplicación en campos como la ciencia, la medicina, la ingeniería y la observación ambiental. Los participantes podrán familiarizarse con los fundamentos físicos y sentar las bases para actividades prácticas.",
        "introduccion_title": "Introducción y Objetivos",
        "introduccion_description": "El objetivo de esta sesión es desarrollar una noción integral del campo de las imágenes térmicas, abarcando desde los fenómenos físicos involucrados hasta sus principales aplicaciones y características.",
        "lecturas_title": "Recursos y Lecturas Previas",
        "lecturas_description": "Para aprovechar al máximo esta sesión, te recomendamos revisar los siguientes recursos:",
        "lecturas_link1": "Experimentos de física con luz infrarroja",
        "lecturas_link2": "Qué es el infrarrojo",
        "lecturas_link3": "Espectrofotometría y Ley de Beer",
        "lecturas_link4": "Blog “Introducción al infrarrojo térmico”",
        "contenido_title": "Desarrollo de la Sesión",
        "contenido_description": "De acuerdo con la metodología Hands-On, esta sesión combinará la exploración de la teoría de mano con su aplicación práctica:",
        "contenido_list_item1": "Imágenes térmicas y aplicaciones: Casos de uso reales, motivación y ejemplos que ilustran el valor de esta tecnología en diversos contextos.",
        "contenido_list_item2": "Luz y radiación: Leyes fundamentales como la de Kirchhoff y la de Planck, visualización de la radiación térmica y conceptos de emisividad y atenuación.",
        "contenido_list_item3": "Imágenes espectrales térmicas: Ley de Beer, emisión atmosférica, dependencia espectral de la emisividad y simulaciones.",
        "contenido_list_item4": "De lo físico al aprendizaje profundo: Aplicaciones recientes de la visión por computadora para estimar parámetros físicos a partir de imágenes térmicas.",
        "contenido_footer": "A lo largo de la sesión, se incluirán actividades prácticas según corresponda.",
        "sesion_title": "Contenido de la Sesión",
        "sesion_presentacion_title": "Presentación en PDF",
        "sesion_presentacion_description": "Puedes navegar por la presentación usando los controles del visor.",
        "sesion_video_title": "Video de la sesión"
    },
    "Sesion10": {
        "sidebar_introduccion": "Introducción y Objetivos",
        "sidebar_lecturas": "Recursos y Lecturas Previas",
        "sidebar_contenido": "Desarrollo de la Sesión",
        "sidebar_actividades": "Actividades y Tareas Posteriores",
        "sidebar_sesion": "Contenido de la Sesión",
        "hero_title": "Optimización",
        "hero_description": "En esta sesión se explorarán los fundamentos de la optimización convexa, desde su definición formal hasta su aplicación en problemas inversos y en aprendizaje profundo. Veremos por qué es tan importante garantizar convexidad, cómo resolver eficazmente estos problemas y cómo enfrentarnos a escenarios mal planteados.",
        "introduccion_title": "Introducción y Objetivos",
        "introduccion_description": "Que los participantes adquieran una comprensión sólida de qué es un problema de optimización convexa, las técnicas para resolverlo, ejemplos de aplicaciones reales y cómo abordar problemas inversos e “ill-posed” usando optimización y redes neuronales.",
        "lecturas_title": "Recursos y Lecturas Previas",
        "lecturas_description": "Para aprovechar al máximo esta sesión, te recomendamos revisar los siguientes recursos:",
        "lecturas_link1": "Introducción a la optimización convexa",
        "lecturas_link2": "Convexidad y el principio de dualidad",
        "lecturas_link3": "IA para problemas inversos emergentes en imágenes computacionales por Shirin Jalali",
        "contenido_title": "Desarrollo de la Sesión",
        "contenido_description": "De acuerdo con la metodología Hands-On, esta sesión combinará la exploración de la teoría de mano con su aplicación práctica:",
        "contenido_list_item1": "Comenzaremos definiendo de manera concisa qué es la optimización convexa y por qué garantizar la convexidad de un problema resulta clave para obtener soluciones únicas y estables.",
        "contenido_list_item2": "Luego, ofreceremos un panorama de las principales familias de métodos de resolución, tanto analíticos como iterativos, para comprender sus ventajas y limitaciones.",
        "contenido_list_item3": "A continuación, presentaremos aplicaciones reales en campos como aprendizaje automático, visión por computador e ingeniería, ilustrando con ejemplos concretos el alcance práctico de la optimización convexa.",
        "contenido_list_item4": "Posteriormente, realizaremos una actividad práctica en la que los asistentes abordarán un problema inverso clásico mediante código, aplicando los conceptos aprendidos.",
        "contenido_list_item5": "Finalmente, analizaremos los desafíos de los problemas mal planteados y debatiremos cómo la integración de redes neuronales puede mejorar la estabilidad y la calidad de las soluciones.",
        "contenido_footer": "A lo largo de la sesión, se incluirán actividades prácticas según corresponda.",
        "sesion_title": "Contenido de la Sesión",
        "sesion_presentacion_title": "Presentación en PDF",
        "sesion_presentacion_description": "Puedes navegar por la presentación usando los controles del visor.",
        "sesion_video_title": "Video de la sesión"
    },
    "Sesion12": {
        "title": "Selecciona tu proyecto"
    },
    "Proyects": {
        "equipo1_title": "Equipo 1",
        "equipo1_abstract": "Este proyecto analiza y compara la cobertura vegetal en Bucaramanga y sus municipios principales mediante segmentación de imágenes. Utilizamos los modelos Grounding DINO y Segment Anything (SAM) para identificar y delimitar áreas de vegetación en entornos urbanos, con el fin de apoyar estudios sobre sostenibilidad y planificación verdes.",
        "equipo2_title": "Equipo 2",
        "equipo2_abstract": "Este proyecto tiene como objetivo aplicar técnicas de procesamiento de lenguaje natural (NLP) y modelos de inteligencia artificial para analizar contenido de publicaciones de grupos de la universidad en Facebook. Mediante web scraping, se recolectan publicaciones públicas del grupo y se procesan para descubrir patrones, emociones, comportamientos frecuentes, entre otros",
        "equipo3_title": "Equipo 3",
        "equipo3_abstract": "Según el más reciente Informe Anual sobre la Calidad del Aire en el Mundo de IQAir, ninguna ciudad colombiana cumple con los estándares de la Organización Mundial de la Salud (OMS), lo que evidencia una crisis ambiental impulsada por emisiones industriales, agropecuarias y de residuos. Frente a este panorama, desarrollamos un sistema de detección remota de metano mediante un filtro lineal espectral aplicado a imágenes hiperespectrales del satélite EnMAP. Nuestra metodología integra preprocesamiento espectral, alineación precisa de firmas de absorción y análisis de covarianza para generar mapas de segmentación que identifican posibles focos de emisión. Los resultados fueron consistentes con reportes locales de emisiones, demostrando el potencial del enfoque para la identificación geoespacial de gases. Este trabajo confirma la viabilidad del uso de imágenes satelitales para el monitoreo ambiental y abre el camino a mejoras mediante inteligencia artificial, con miras a sistemas más precisos, automatizados y escalables para el control de emisiones.",
        "equipo4_title": "Equipo 4",
        "equipo4_abstract": "Este proyecto tuvo como objetivo la creación de un conjunto de datos sintético para escenarios Non-Line-of-Sight (NLoS), compuesto por pares de imágenes transitorias (volúmenes espacio-tiempo) y mapas de profundidad, generados mediante el motor de renderizado Mitsuba 3. Para ello, se utilizaron geometrías 3D en formato OBJ, que fueron preprocesadas y configuradas cuidadosamente para su correcta integración en el entorno de simulación. Además, se implementaron técnicas de aumento de datos con el fin de enriquecer la variabilidad del conjunto generado. Como resultado, se obtuvo un dataset completo y estructurado, útil para tareas de investigación y entrenamiento de modelos relacionados con la visión por computadora.",
        "equipo5_title": "Equipo 5",
        "equipo5_abstract": "Este proyecto propone un algoritmo no supervisado para la estimación de profundidad en videos de endoscopia, utilizando aprendizaje profundo. Se aplica una técnica de adaptación mediante Low-Rank Adaptation (LoRA) a un modelo de estimación de disparidad, permitiendo su especialización en el dominio médico sin necesidad de datos anotados. El entrenamiento se realiza sobre un conjunto de imágenes de endoscopia, con el objetivo de obtener mapas de profundidad precisos que puedan asistir en tareas clínicas y quirúrgicas.",
        "equipo6_title": "Equipo 6",
        "equipo6_abstract": "Desarrollamos un sistema de detección de minas antipersonales basado en aprendizaje profundo utilizando imágenes térmicas aéreas del dataset público 'Dataset of Thermographic Images for the Detection of Buried Landmines'. Nuestra metodología combina técnicas de preprocesamiento de imágenes y ajuste fino de arquitecturas de vanguardia como ResNet, ConvNeXt, Vision Transformer (ViT) y Swin Transformer para la tarea de clasificación binaria (mina / no mina), alcanzando una exactitud del 99.23%, precisión del 100%, sensibilidad del 94.87% y especificidad del 100%, superando el estado del arte. Adicionalmente, realizamos un proceso de anotación manual de 360 imágenes para la tarea de detección y entrenamos YOLOv11, obteniendo una precisión del 99.4%, sensibilidad del 97.8% y un mAP@50 de 99.3%, estableciendo un baseline sólido para tareas de localización. Este trabajo destaca el potencial del aprendizaje profundo junto con las imágenes térmicas en tareas críticas de seguridad humanitaria, abriendo camino hacia soluciones automatizadas y robustas en la remoción de minas antipersonales.",
        "equipo7_title": "Equipo 7",
        "equipo7_abstract": "El proyecto propone desarrollar un modelo de deblurring (restauración de imágenes desenfocadas) que utilice mapas de profundidad como guía estructural y priorización de regiones, mejorando los métodos actuales basados únicamente en imágenes RGB. La investigación incluye el estudio del desenfoque por profundidad (DoF), la creación de un dataset sintético con imágenes RGB, mapas de profundidad y versiones borrosas, y el diseño de una arquitectura de red neuronal que integre esta información geométrica para recuperar detalles con mayor precisión en áreas críticas, seguido de su entrenamiento y evaluación.",
        "equipo8_title": "Equipo 8",
        "equipo8_abstract": "Este proyecto tiene como objetivo el análisis, georreferenciación y visualización de nubes de puntos obtenidas mediante tecnología LiDAR (Light Detection and Ranging). A través del procesamiento de datos espaciales tridimensionales, se busca extraer información relevante del entorno físico, facilitando la interpretación estructural y geoespacial del terreno. El flujo de trabajo incluye la lectura y limpieza de datos en formato .bag, la corrección y transformación de coordenadas para una adecuada georreferenciación, y la visualización interactiva de la nube de puntos. Este proyecto es aplicable a múltiples áreas, como cartografía, ingeniería civil, arqueología, medio ambiente y planificación urbana.",
        "equipo9_title": "Equipo 9",
        "equipo9_abstract": "En este trabajo proponemos una metodología para la segmentación precisa de objetos en representaciones tridimensionales obtenidas mediante redes de campos radiantes neuronales (NeRF). La segmentación de objetos específicos en escenas NeRF presenta desafíos debido a la necesidad de mantener consistencia y precisión en múltiples vistas 3D. Para abordar este problema, integramos eficazmente el modelo Segment Anything Model (SAM), permitiendo realizar segmentaciones mediante indicaciones textuales o puntos interactivos directamente sobre las imágenes. Nuestra propuesta fue evaluada con dos escenas adicionales de la Universidad Industrial de Santander, cada una compuesta por 200 imágenes, mostrando resultados robustos y coherentes en múltiples perspectivas. Además, incorporamos la plataforma nerfstudio, facilitando la interacción del usuario y mejorando significativamente la experiencia en visualización y segmentación tridimensional."
    }
}